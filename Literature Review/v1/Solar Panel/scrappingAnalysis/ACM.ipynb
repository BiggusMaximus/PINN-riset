{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from csv import DictWriter\n",
    "from threading import Thread\n",
    "import os, csv, re, queue, time, winsound, traceback\n",
    "import pycountry\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument('--ignore-certificate-errors')\n",
    "chrome_options.add_argument('--ignore-ssl-errors')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "chrome_options.add_argument('--disable-gpu')\n",
    "chrome_options.add_argument('--incognito')\n",
    "chrome_options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "chrome_options.add_argument(\"--start-maximized\")\n",
    "# chrome_options.add_argument(\"--headless\")\n",
    "caps = webdriver.DesiredCapabilities().CHROME\n",
    "caps[\"pageLoadStrategy\"] = \"normal\"\n",
    "service = Service(ChromeDriverManager().install())\n",
    "\n",
    "LINK = 'https://dl.acm.org/action/doSearch?fillQuickSearch=false&target=advanced&field1=AllField&text1=LEACH+AND+WSN+AND+ENERGY&pageSize=50&expand=all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "link ='https://dl.acm.org/action/doSearch?fillQuickSearch=false&target=advanced&field1=AllField&text1=LEACH+AND+WSN+AND+ENERGY&pageSize=50&expand=all'\n",
    "\n",
    "driver.get(link)\n",
    "allow_all_cookies_button = WebDriverWait(driver, 10).until(\n",
    "    EC.visibility_of_element_located((By.ID, \"CybotCookiebotDialogBodyLevelButtonLevelOptinAllowAll\"))\n",
    ")\n",
    "\n",
    "# Click the 'Allow all cookies' button\n",
    "allow_all_cookies_button.click()\n",
    "html = driver.page_source\n",
    "driver.close()\n",
    "soups = BeautifulSoup(html, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title:\n",
      "\t\t\t\tEnergy-Aware MAX-LEACH Routing Protocol for Homogeneous and Heterogeneous WSNs\n",
      "link:\n",
      "\t\t\t\thttps://dl.acm.org/doi/10.1007/s11277-023-10673-0\n",
      "number_of_citation:\n",
      "\t\t\t\t0\n",
      "article_type:\n",
      "\t\t\t\tresearch-article\n",
      "publisher:\n",
      "\t\t\t\tACM\n",
      "keyword:\n",
      "\t\t\t\tAverage energy,Sink,Cluster head,Energy consumption,Heterogeneous WSN,LEACH protocol,Network lifetime\n",
      "abstract:\n",
      "\t\t\t\tThe Energy-Efficient wireless sensor network is needed in the present-day Scenario. The main problem in the area of WSN is energy consumption or low battery power. In such a case the best routing protocols are required to reduce the energy consumption and to improve the network lifetime. This paper is focused on how to minimize the nodes' energy depletion and then how to rise the network lifetime by efficient routing protocols in the WSN. In this paper, we have proposed an Energy-Aware Routing protocol for Homogeneous and Heterogeneous WSNs called MAX LEACH. The proposed protocol improves the total network lifetime. The proposed protocol is simulated using MATLAB and observed that the network lifetime was improved when compared to existing Homogeneous and Heterogeneous protocols. Various parameters like alive nodes, dead nodes, throughput, residual energy, and packet transmission from nodes to the sink are also compared.\n",
      "publish_date:\n",
      "\t\t\t\t01 August 2023\n",
      "publication_title:\n",
      "\t\t\t\tWireless Personal Communications, Volume 132, Issue 2\n",
      "authors:\n",
      "\t\t\t\tMr. Mr. Suman Jonnalagadda,Dr. Dr. Shyamala Kattula,Mrs. Mrs. Roja Guntuku\n",
      "affiliations:\n",
      "\t\t\t\t(CSE Department, B V Raju Institute of Technology, Narsapur, Medak, Telangana, Indiahttps://orcid.org/0000-0001-8386-4557),(CSE Department, University College of Engineering, Osmania University, Hyderabad, Telangana, India),(CSE Department, University College of Engineering, Osmania University, Hyderabad, Telangana, India)\n",
      "countries:\n",
      "\t\t\t\tIndia,India,India\n"
     ]
    }
   ],
   "source": [
    "article = soup.find_all('li', class_='search__item issue-item-container')[1]\n",
    "\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "try:\n",
    "    link_article        = 'https://dl.acm.org' + article.find('h5', class_='issue-item__title').find('a')['href']\n",
    "    article_type       = article.find('div', class_='issue-heading').get_text()\n",
    "    article_title = article.find('h5', class_='issue-item__title').get_text()\n",
    "\n",
    "    driver.get(link_article)\n",
    "    driver.implicitly_wait(5)\n",
    "    allow_all_cookies_button = WebDriverWait(driver, 10).until(\n",
    "        EC.visibility_of_element_located((By.ID, \"CybotCookiebotDialogBodyLevelButtonLevelOptinAllowAll\"))\n",
    "    )\n",
    "    allow_all_cookies_button.click()\n",
    "    html = driver.page_source\n",
    "\n",
    "    article_soup = BeautifulSoup(html, 'html.parser')\n",
    "    publication_title = article_soup.find('div', class_='core-enumeration')\n",
    "    if publication_title != None:\n",
    "        publication_title = publication_title.get_text()\n",
    "    else:\n",
    "        publication_title = article_soup.find('div', property='isPartOf')\n",
    "        publication_title = publication_title.get_text()\n",
    "            # if publication_title != None:                   \n",
    "\n",
    "    info_click = driver.find_element(By.XPATH, '//*[@id=\"article_collateral_menu\"]/ul/li[1]/a')\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView(true);\", info_click)\n",
    "\n",
    "    info_click =  WebDriverWait(driver, 30).until(\n",
    "        EC.element_to_be_clickable(\n",
    "            (By.XPATH, '//*[@id=\"article_collateral_menu\"]/ul/li[1]/a'))\n",
    "    )\n",
    "    info_click.click()\n",
    "    html = driver.page_source\n",
    "    article_soup_info = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    contribution_button = driver.find_element(By.ID, 'tab-contributors-label')\n",
    "    contribution_button.click()\n",
    "\n",
    "    contribution_button =  WebDriverWait(driver, 30).until(\n",
    "        EC.visibility_of_element_located((By.ID, \"tab-contributors\"))\n",
    "    )\n",
    "    html = driver.page_source\n",
    "    article_soup_author = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    number_of_citation = article_soup.find('span', class_=\"citation\")\n",
    "\n",
    "    if number_of_citation:\n",
    "        number_of_citation = number_of_citation.get_text().replace('citation', '')\n",
    "    else:\n",
    "        number_of_citation = 'none'\n",
    "\n",
    "    abstract = article_soup.find('section', id=\"abstract\") \n",
    "\n",
    "    if abstract != None:\n",
    "        abstract = abstract.get_text().replace(\"Abstract\", '')\n",
    "    else:\n",
    "        abstract = article_soup.find('section', id=\"author-abstract\") \n",
    "        abstract = abstract.get_text().replace(\"Abstract\", '')\n",
    "        \n",
    "    publication_date = article_soup.find('span', class_='core-date-published').get_text()\n",
    "\n",
    "    keywords = article_soup_info.find('section', property='keywords')\n",
    "    if keywords != None:\n",
    "        keywords = keywords.find_all('li')\n",
    "        keywords = ','.join([keyword.get_text() for keyword in keywords])\n",
    "    else:\n",
    "        keywords = 'none'\n",
    "\n",
    "    author_informations = article_soup_author.find('div', class_='contributors').find_all('span', property=\"author\")\n",
    "    authors = ''\n",
    "    countries = ''\n",
    "    affiliations = ''\n",
    "    count = 0\n",
    "\n",
    "    for author_information in author_informations:\n",
    "        author = author_information.find('a').get_text()\n",
    "        affiliation = author_information.find('div', class_='content').get_text()\n",
    "        affiliation = affiliation.replace('View Profile', '')\n",
    "\n",
    "        authors += author\n",
    "        affiliations += f'({affiliation})'\n",
    "\n",
    "        affiliation = affiliation.split(', ')\n",
    "        country = affiliation[len(affiliation)-1]\n",
    "        countries += country\n",
    "\n",
    "        if count < len(author_informations)-1:\n",
    "            authors         += ','\n",
    "            countries       += ','\n",
    "            affiliations    += ','\n",
    "        count += 1\n",
    "    \n",
    "    occurrences = countries.split(',')\n",
    "    found_countries = []\n",
    "\n",
    "    for country in pycountry.countries:\n",
    "        for occurrence in occurrences:\n",
    "            if country.name in occurrence:\n",
    "                found_countries.append(country.name)\n",
    "\n",
    "    countries = ','.join(found_countries)\n",
    "        \n",
    "\n",
    "    \n",
    "    row_data = {\n",
    "        'title'                         : article_title,\n",
    "        'link'                          : link_article,\n",
    "        'number_of_citation'            : number_of_citation,\n",
    "        'article_type'                  : article_type,\n",
    "        'publisher'                     : 'ACM',\n",
    "        'keyword'                       : keywords,\n",
    "        'abstract'                      : abstract,\n",
    "        'publish_date'                  : publication_date,\n",
    "        'publication_title'             : publication_title,\n",
    "        'authors'                       : authors,\n",
    "        'affiliations'                  : affiliations,\n",
    "        'countries'                     : countries\n",
    "    }\n",
    "    \n",
    "    for col in row_data.keys():\n",
    "        print(f\"{col}:\\n\\t\\t\\t\\t{row_data[col]}\")\n",
    "\n",
    "except Exception as e:\n",
    "        print(\"\\n\"*3)\n",
    "        print(\"== ! Error ! ==\"*10)\n",
    "        print(\"\\n\"*1)\n",
    "        print(f\"Failed to retrieve article: \\n{article_title}\\n{link_article}\\n{e}\")\n",
    "        traceback.print_exc()\n",
    "        print(\"\\n\"*3)\n",
    "        print(\"== ! Error ! ==\"*10)\n",
    "        print(\"\\n\"*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
